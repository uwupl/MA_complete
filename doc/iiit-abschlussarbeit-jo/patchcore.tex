% -*- TeX -*- -*- DE -*-

\chapter{PatchCore \cite{patchcore}}\label{ch:PatchCore}
\section{Einleitung}\label{sec:EinleitungPatchCore}
Die Methode \textbf{PatchCore} wurde erstmals am 15. Juni 2021 in Zusammenarbeit der Universität Tübingen und Amazon AWS im Paper \glqq Towards Total \ 
Recall in Industrial Anomaly Detection\grqq{} veröffentlicht. \ 
In seiner zweiten Fassung vom 5. Mai 2022 wurde das Paper bei der Konferenz CVPR 2022 (Computer Vision and Pattern Recognition) akzeptiert und mit \ 
über 290 Zitierungen eines der populärsten Paper im Bereich der Unüberwachten Anomaliedetektion.\\
Die Grundlage dieses Ansatzes sind wiederum \glqq Einbettungen\grqq{} (Embeddings) von Merkmalen (Features), \ 
die aus den Eingabebildern mithilfe eines auf \glqq ImageNet\grqq{} vortrainiertem \glqq Convolutional Neural Network (CNN)\grqq{} erzeugt werden.\
Damit ähnelt sich die Methode PatchCore sowohl SPADE\ref{sec:SPADE}, also auch PaDiM\ref{sec:PaDiM} und greift die in \ref{subsec:ResNetsAsFeatureExtractor} \
beschriebene Vorgehensweise auf.\
Wie wir später sehen werden, unterscheidet sich der Einbettungsprozess jedoch recht deutlich von den bisherigen Methoden.\
% Wie in einigen vorangegangenen Veröffentlichungen im Bereich der Unüberwachten Anomaliedetektion, werden auch hier die Features in \glqq Patches\grqq{} \ 
% unterteilt, um die Lokalität der Anomalien zu erhalten. Diese werden folgend als \textbf{\glqq Patch Features\grqq{}} bezeichnet.\
Weiter wird die eigentliche Anomaliedetektion, wie bereits bei der Methode SPADE mithilfe einer Nächsten Nachbar Suche \ 
(Nearest Neighbor Search; NN) in einer \glqq Memory-Bank \grqq{} durchgeführt.\
Die wesentliche Weitereentwicklung gegenüber SPADE liegt vor allem in der Methode, wie die Memory-Bank aufgebaut wird. Durch die Auswahl möglichst representativer \
Elemente in der Memory Bank, kann die Anzahl der Elemente in der deutlich reduziert werden, was einer Reduzierung der Laufzeit bedeutet.\\
Auch gut 2 Jahre nach Veröffentlichung ist die PatchCore Methode insbesondere auf dem MVTecAD-Datensatz\ref{sec:DatensatzMVTecAD} mit einer Genauigkeit (Auccuracy) \ 
von maximal \num{99,6}\% (\glqq PatchCore Ensemble\grqq{}) absolut konkurrenzfähig und wird in vielen Veröffentlichungen als \glqq State-of-the-Art\grqq{} Methode verwendet.\\
Im Laufe dieses Kapitels soll zunächst die Funktionsweise der Methode PatchCore erläutert werden. Anschließend evaluieren wir die Originalmethode im Hinblick auf Laufzeit und Genauigkeit. \
Im sich dann anschließenden Teil werden zahlreiche Modifikationen besprochen, die versuchen, die Laufzeit auf zu Reduzieren und dabei möglichst viel der Genauigkeit zu erhalten.\

% Zunächst wollen wir die grundsätzliche Funktionsweise der Methode PatchCore erläutern. Anschließend bewerten wir die Methode im Hinblick auf Laufzeit und Genauigkeit. \
% Anschließend werden zahlreiche Adaptionen der Methode vorgestellt, die im Sinne des Ziels dieser Arbeit die Laufzeit der Methode reduzieren und dabei die Genauigkeit möglichst wenig beeinträchtigen sollen.\
\section{Funktionsweise}
\label{sec:Funktionsweise}
unächst kann zwischen zwei Phasen unterschieden werden: Der Trainingsphase und der Testphase.\
In der Trainingsphase werden die \glqq (locally aware) \textbf{Patch Features}\grqq{} aus den Trainingsbildern (\glqq Nominal Samples\grqq{}) extrahiert. \ 
Hierzu wird ein \glqq Pretrained Encoder\grqq{} verwendet, analog zu \ref{subsec:ResNetsAsFeatureExtractor}.\
Anschließend findet eine Unterabtastung bzw. eine Auswahl der Patch Features statt, die in der \glqq Memory Bank\grqq{} gespeichert werden. \ 
Dieser Vorgang wird als \glqq Coreset Subsampling\grqq{} bezeichnet.Ist diese Memory Bank erzeugt, ist die Methode initialisiert und das Training abgeschlossen.\ 
In der Testphase werden die Patch Features auf die gleiche Weise aus den \glqq Test Samples\grqq{} extrahiert, wie in der Trainingsphase. Jedes dieser Patch Features wird nun mit den Patch Features in der Memory Bank verglichen.\ 
Dies geschieht mit einer \glqq Nearest Neighbor Search\grqq{} (NN). Aus den Distanzen zum Nächsten Nachbarn kann dann, wie in \ref{sec:PaDiM} eine räumlich aufgelöste anomaliekarte erzeugt werden.\ 
Auf Grundlage dieser Anomaliekarte geschieht dann die Instanzklassifizierung als nominal oder anomal. Nachfolgende Abbildung \ref{fig:PatchCore}, die aus der Veröffentlichung übernommen wurde, zeigt \ 
die Funktionsweise der Methode PatchCore.\
\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{bilder/patchcore.png}
    \caption{PatchCore}
    \label{fig:PatchCore}
\end{figure}
\subsection{Erzeugen der Patch Features}\label{subsec:ErzeugenDerPatchFeatures}
Zunächst werden einige Notationen definiert, die im Folgenden verwendet werden. Es wird sich dabei auf die Notationen aus der Veröffentlichung bezogen.\
So wird die Menge aller Trainingsbilder als $\mathcal{X}_{train}$ bezeichnet. Die Menge aller Testbilder als $\mathcal{X}_{test}$.\
Für den Trainingsdatensatz gilt im Sinne der Unüberwachtheit, dass es sich um ausschließlich nominale Samples handelt. Im Testdatensatz können sowohl nominale als auch anomale Samples enthalten sein.\
% Werden nominale Samples mit $0$
Bezeichnen wir die wahre Klassenzugehörigkeit eines Bildes $x$ als $y_{x}$, so kann diese entweder $0$ (nominal) oder $1$ (anomal) sein. Für den Trainingsdatensatz gilt dann:\
$\forall x \in \mathcal{X}_{train}: y_{x} = 0$ und für den Testdatensatz $\forall x \in \mathcal{X}_{test}: y_{x} \in \{0,1\}$.\\
Den bereits in \ref{sec:SPADE} und \ref{sec:PaDiM} angetroffenen \glqq Pretrained Encoder\grqq{} wird als $\phi$ bezeichnet.\
Es wird dabei, wie bereits gesehen, nicht der Ausgang dieses Netzwerkes benutzt, sondern die Feature Maps aus einer bestimmten Schicht $j$ des Netzwerkes. \
Im Falle von ResNets, die auch in dieser Veröffentlichung hauptsächlich verwendet werden, ist $j\in \{1,2,3,4\}$.\ 
$j$ wird folgend auch als \glqq Hierarchielevel\grqq{} bezeichnet und spielt eine wichige Rolle.\
$\phi_{i,j} = \phi_{j}(x_{i})$ bezeichnet die Feature Map des Bildes $x_{i}\in \mathcal{X}$ aus dem Hierarchielevel $j$.\
Wie bereits in \ref{subsec:SPADEResults} diskutiert, ist eine sinnvolle Auswahl der Hierarchielevel eine wichtige Voraussetzung für gute Ergebnisse.\
Auch die Autoren von PatchCore weisen auf diese Problemstellung hin. Man könne, wie bei SPADE, die letzte Ebene in der Merkmalshierarchie des Netzes verwenden. \
Dies bringe aber die folgenden zwei Probleme mit sich. Erstens gehe dabei mehr lokalisierte nominale Informationen verloren. Das sei während der Trainingsphase kritisch, \
weil die Arten von Anomalien, die zum Testzeitpunkt auftreten, nicht im Voraus bekannt seien und die möglichst vollständige Erfassung des Normals notwendig sei.\
Zweitens seien die sehr tiefen und abstrakten Merkmale in den vortrainierten ImageNet-Netzwerken auf die Aufgabe der Klassifizierung natürlicher Bilder ausgerichtet, \ 
welche nur wenig direkte Überschneidungen mit der hier vorliegenden Aufgabe der industriellen aufweise. \
Es wird deshalb vorgeschlagen, Merkmale aus den mittleren Hierarchieleveles zu verwenden. Das entspricht bei ResNets $j\in \{2,3\}$.\
Wie in \ref{fig:ResNetPyramid} zu erkennen, handelt es sich bei $\phi_{i,j}$ um einen dreidimensionalen Tensor: $\phi_{i,j}\in \mathbb{R}^{c^{*}\times h^{*}\times w^{*}}$\
mit $c^{*}$ als Tiefe der Feature Maps, $h^{*}$ als Höhe und $w^{*}$ als Breite. \
$\phi_{i,j}(h,w)\in\mathbb{R}^{c^{*}}$ bezeichnet dann den zur Position $h\in\{1,...,h^{*}\}$ und $w\in\{1,...,w^{*}\}$ gehörenden Vektor der Länge $c^{*}$.\
Unter der Annahmen, dass die Größe des Feldes im Originalbild $x_{i}$, das Einfluss auf ein $\phi_{i,j}(h,w)$ nimmt (\glqq Receptive Field\grqq{}), \
ausreichend groß ist, um einen ausreichenden räumlichen Kontext zu erfassen, eignet sich dieser Vektor als \glqq Patch Feature\grqq{} für eine gegenüber \ 
räumlichen Variationen robuste Anomaliedetektion.\\
Um diese wünschenswerte Annahme zu erfüllen, wird eine Aggregation der lokal umliegenden Regionen (\glqq local Neighborhood Aggregation\grqq{}) durchgeführt, das nachfolgend \
vorgestellt wird und die Größe des Receptive Fields steuert.\\
Dafür wird die oben eingeführte Notation für $\phi_{i,j}(h,w)$ um eine ungerade Feldgröße (\glqq patchsize\grqq{}) $p$ erweitert, die die benachbarten Feauture Vektoren \
mit einbezieht. Zunächst wird diese Nachbarschaft wie folgt definiert:\
$$
\mathcal{N}_{p}^{(h,w)} = \left\{(a,b)| a \in \left[h-\left\lfloor \frac{p}{2}\right\rfloor,...,h+\left\lfloor \frac{p}{2} \right\rfloor\right], b \in \left[w-\left\lfloor \frac{p}{2}\right\rfloor,...,w+\left\lfloor \frac{p}{2}\right\rfloor\right]\right\}
$$ 
Damit ergeben sich schließlich ein \glqq Patch Feature\grqq{} zu\
$$
\phi_{i,j}\Big(\mathcal{N}_{p}^{(h,w)}\Big) = f_{agg}\Big(\{\phi_{i,j}(a,b)| (a,b) \in \mathcal{N}_{p}^{(h,w)}\}\Big),
$$
wobei $f_{agg}$ eine Aggregationsfunktion ist. Die Aggregationsfunktionsfunktion, die in der PatchCore Methode verwendet wird, ist ein adptives \glqq Average Pooling\grqq{}, \
in einer Dimension, die unabhängig von der Länge der Eingangsfeature, immer eine feste Länge $d$ ausgibt.\\
Da diese Operation für alle Paare von $(h,w)$ mit $h\in\{1,...,h^{*}\}$ und $w\in\{1,...,w^{*}\}$ durchgeführt wird, wird die Auflösung der Feature Map erhalten.
Für einen gesamten Feature Map Tensor ergibt sich dementsprechend:\
$$
\mathcal{P}_{s,p}\left(\phi_{i,j}\right) = \left\{\phi_{i,j}\Big(\mathcal{N}_{p}^{(h,w)}\Big)| h\in\{1,...,h^{*}\}, w\in\{1,...,w^{*}\}\right\}
$$
Wie bereits erwähnt, geschieht diese Operation für verschiedene Hierarchielevel $j$.\ Weil die Auflösung der Feature Maps mit steigendem Hierarchielevel abnimmt, \
wird $\mathcal{P}_{s,p}\left(\phi_{i,j+1}\right)$ berechnet und anschließend auf die Auflösung von $\mathcal{P}_{s,p}\left(\phi_{i,j}\right)$ bilinear interpoliert.\ 
Jedes Element wird dann mit dem korrespondieren Element, also dem Element an der gleichen Stelle, aggregiert.\
Würde auf eine Auswahl der Patch Feature, wie im folgenden Abschnitt erläutert, verzichtet, würde sich folgende Memory-Bank ergeben:
$$
\mathcal{M} = \bigcup_{x_i\in\mathcal{X}_{train}}\mathcal{P}_{s,p}\left(\phi_{i,j}\right)
$$
\subsection{Coreset Subsampling}\label{subsec:CoresetSubsampling}
Insbesondere, wenn $\mathcal{X}_{train}$ eine große Kardinalität hat, also viele Bilder hat, wird die Memory-Bank $\mathcal{M}$ sehr groß. Wie bereits in \ref{sec:SPADE} festgestellt \
ist diese Kardinalität besonders laufzeitkritisch, weil die Nächste Nachbar Suche in der Memory-Bank mit einer Komplexität von $\mathcal{O}(n)$ berechnet wird. \ 
Wie bereits in \ref{sec:PaDiM} zu sehen, ist ein \glqq patchbasierter\grqq{} Vergleich zwischen allen Elementen in $\mathcal{M}$ und allen Elemnten in $\mathcal{P}_{s,p}\left(\phi_{i,j}\right)$ \
ein notwediger Schritt, nicht nur um die Anomaliekarte zu erstellen, die in dieser Arbeit ohnehin von keinem großen Interesse ist, sondern auch um eine robuste und \ 
präzise Instanzklassifizierung durchzuführen. Für die Laufzeitoptimierung ist es also wünschenswert, die Kardinalität der Memory-Bank zu reduzieren.\\
Auf der anderen Seite müssen die Elemente in $\mathcal{M}$ möglichst gut nominale Eigenschaften abbilden, um eine gute Anomaliedetektion zu ermöglichen.\
Wie in der Veröffentlichung gezeigt wird, (§4.4.2 - Importance of Coreset Subsampling) führt der naive Ansatz, zufällig Elemente aus $\mathcal{M}$ auszuwählen, \
nicht zu zufriedenstellenden Ergebnissen.\\
Das von PatchCore zugrundeliegenden Konzept setzt genau hier an. Es soll eine Teilmenge $\mathcal{S}\subset \mathcal{A}$ gefunden werden, bei der die Problemlösung \
über $\mathcal{A}$ am ehesten und vor allem schneller durch die über $\mathcal{S}$ berechnete Lösung approximiert werden kann. Dabei ist die Methode, \
die zu einer solchen Teilmenge führt, problemspezifisch. Im Falle von PatchCore wird eine Berechnung von Nächsten Nachbarn durchgeführt, \
weswegen gemäß \cite{sener2018active} ein \glqq MiniMax-Funktion\grqq{} sich anbietet, um eine annähernd ähnliche Abdeckung der $\mathcal{M}$ mit $\mathcal{M_{C}}$ zu erreichen.\
Dies kann wie folgt gelöst werden:\
$$
\mathcal{M_{C}^{*}} = \underset{\mathcal{M}_{C}\subset\mathcal{M}}{\arg\min}\underset{m\in\mathcal{M}}{\max}\underset{n\in\mathcal{M_{C}}}{\min}\left\|m-n\right\|_{2}
$$
Die exakte Berechnung von $\mathcal{M_{C}^{*}}$ ist NP-schwer, also nicht in polynomieller Zeit berechenbar.\
Es handelt sich zwar um einen Prozess, der nicht während der Inferenz durchgeführt werden muss, sondern einmalig während der Trainingsphase, \
aber es muss dennoch mit iterativen, approximierenden Verfahren gearbeitet werden.\\
Aus \cite{sener2018active} wird ein \glqq Greedy Algorithmus\grqq{} übernommen, der iterativ Elemente aus $\mathcal{M}$ auswählt, die die größte Distanz zu allen bereits ausgewählten Elementen haben.\
Um die Laufzeit des Subsamplings weiter zu reduzieren, wird das \glqq Johnson-Lindenstrauss Lemma\grqq{}\cite{johnsonlindenstrauss} verwendet, um die Dimensionalität der Elemente $m\in\mathcal{M}$ \ 
durch zufällige lineare Projektion $\psi: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d^{*}}$ mit $d^{*}<d$ zu reduzieren. Anschaulich kann dies durch eine Punktwolke erklärt werden, die aus zufälligen Blickwinkeln betrachtet wird, wodurch die 3-D-Struktur als 2-D Struktur\
angenähert wird. (TODO --> Algorithmus?)\\
\subsection{Bestimmen des Anomaliegrades}\label{subsec:BestimmenDesAnomaliegradesPatchcore}
Wie bereits in der Einleitung zu diesem Katpitel erwähnt, ist die Grundlage der Bestimmung des Anomaliegrades die Distanz zu den Nächsten Nachbarn in der Memory-Bank.\ 
Das gilt sowohl für die Anomaliekarte bzw. die Segmentierung, als auch für die Instanzklassifizierung. \
Zunächst muss während der Inferenz aus einem Testbild $x_{i}\in\mathcal{X}_{test}$ die Patch Features extrahiert werden. Dies geschieht auf die gleiche Weise, wie in der Trainingsphase:\
$$
\mathcal{P}\left(x_{i}\right)= \mathcal{P}_{p}\left(\phi_{j}\left(x_{i}\right)\right)
$$
Diese Menge $\mathcal{P}\left(x_{i}\right)$ enthält nun die Patch Features $m^{test}$ des Testbildes $x_{i}$. Nun gilt es zu jedem Patch Feature in $\mathcal{P}\left(x_{i}\right)$ \
den Nächsten Nachbarn in der Memory Bank $\mathcal{M}$ zu finden:\
$$
m^{*} = \underset{m\in\mathcal{M}}{\arg\min}\left\|m-m^{test}\right\|_{2}, \forall m^{test}\in\mathcal{P}\left(x_{i}\right)
$$
Es gilt zu beachten, dass jedes $m^{test}$ zu einer Position $(h,w)$ im Bild $x_{i}$ gehört.\
So kann eine räumlich aufgelöste Anomaliekarte $M$ erzeugt werden, die die Distanz zu den Nächsten Nachbarn in der Memory-Bank enthält:
$$
% M = \left\{m^{*}(h,w)| m^{*} = \underset{m\in\mathcal{M}}{\arg\min}\left\|m-m^{test}\right\|_{2}, \forall m^{test}\in\mathcal{P}\left(x_{i}\right)\right\}
M = \Big(\left\|m^{*}_{h,w}-m^{test}_{h,w}\right\|_{2}\Big)_{h,w},\forall \left(h,w\right)\in\{1,...,h^{*}\}\times\{1,...,w^{*}\} % m^{test}_{h,w}\in\mathcal{P}\left(x_{i}\right)
$$
Diese Anomaliekarte $M$ kann schließlich mittels bilinearer Interpolation und einer anschließenden Glättung auf die Auflösung des Originalbildes $x_{i}$ gebracht werden, wodurch eine \
pixelweise Klassifikationskarte möglich wird. Weil dies in dieser Arbeit nicht von Interesse ist, wird darauf nicht weiter eingegangen.\\
Die Instanzklassifizierung könnte nun analog zu PaDiM (\ref{subsec:PaDiMFunktionsweise}) durch Maximalwerbildung durchgeführt werden.\
Die Autoren von PatchCore gehen ähnlich vor, fügen jedoch noch einen Gewichtungsschritt hinzu.\
Zunächst wird ganz analog vorgegangen und die maximale Distanz zu den Nächsten Nachbarn herangezogen, was nichts anderes als der Maximalwert der Anomaliekarte $M$ ist.\
$$
m^{test,*}, m^{\star}=\underset{m^{test}\in\mathcal{P}(x_{i})}{\arg\max}\underset{m\in\mathcal{M}}{\arg\min}\left\|m-m^{test}\right\|_{2}
$$
$$
s^{*}=\left\|m^{test,*}-m^{\star}\right\|_{2}=\max\{M\}
$$
Die Gewichtung schließt die nächsten $b$ Patch Features in $M$ zu $m^{\star}$ mit ein. Diese Menge notieren wir als $\mathcal{N}_{b}\left(m^{\star}\right)$.\
Der Gedanke hinter dieser Gewichtung ist, den Anomaliegrad $s$ dann zu erhöhen, wenn die Feature Patches in $\mathcal{N}_{b}\left(m^{\star}\right)$ selbst \
weit entfernt vom Anomaliekandidaten Patch Feature $m^{\star}$ sind und es sich somit ohnehin um seltene nominale Patch Features handelt. \
Der finale, für die Instanzklassifiziergung entscheidende Anomaliegrad $s$ ergibt sich dann zu:\
$$
s = \left(1-\frac{e^{\left\|m^{\star}-m^{test,*}\right\|_{2}}}{\sum\nolimits_{m\in\mathcal{N}_{b}\left(m^{\star}\right)}e^{\left\|m-m^{test,*}\right\|_{2}}}\right) \cdot s^{*}
$$
Durch diese Gewichtung wird die Instanzklassifizierung robuster und erhöht die Instanzklassifiziergungsgenauigkeit, wodurch es eine weitere Weitereentwicklung gegenüber PaDiM darstellt.\
\section{Ergebnisse und Diskussion der Originalmethode}\label{sec:ErgebnisseUndDiskussionDerOriginalmethode}
In diesem Abschnitt werden die Ergebnisse der Originalmethode PatchCore vorgestellt und diskutiert.\
Dies soll vor allem im Hinblick auf die Eignung für eine Implementierung auf einem ressourcenbeschränkten Gerät, nämlich einem RaspberryPi 4B (\ref{sec:RaspberryPi4B}) geschehen.\
Es wird sich dabei auf den hier verwendeten Datensatz MVTecAD (\ref{sec:DatensatzMVTecAD}) bezogen. Weitere Datensätze, die in der Veröffentlichung verwendet wurden, \
werden mit dem Verweis auf die Veröffentlichung nicht weiter betrachtet. Die zur Evaluation herangezogene Metrik ist AUROC (\ref{sec:AUROC}).\\
Wie bereits in der Einleitung erwähnt, ist die Methode PatchCore grundsätzlich in der Lage, sehr hohe Instanzklassifiziergungsgenauigkeiten zu erreichen, die auch zwei Jahre nach \
Veröffentlichung noch zu den besten gehören. Erreicht wird dies teilweise durch ein Ensemble von verschiendenen Feature Extraktoren bzw. Backbones und höhere Auflösungen.\
So wird ein \glqq DenseNet 201\grqq{}\cite{densenet}, ein \glqq ResNext 101\grqq{}\cite{resnext} und ein bereits bekanntes Wide ResNet mit 101 Schichten\cite{wideresnet} verwendet. \
Steht eine GPU zur Verfügung, welche, wie in \ref{tab:model-runtimes} zu sehen, die Laufzeit von CNNs deutlich reduziert, können selbst mit einer solchen Konfiguration, bestehend aus \
vielen Backbones, einigermaßen schnelle Inferenzzeiten erreicht werden.\
Da die Zielsetzung dieser Arbeit jedoch die Implementierung auf einem RaspberryPi 4B ist und bereits gezeigt wurde, dass das Ausführen von CNNs auf einem solchen Gerät \
äußerst laufzeitkritisch ist, ist eine solche Konfiguration im Kontext dieser Arbeit nicht sinnvoll.\
Beschränken wir uns auf Konfigurationen, mit nur einem Backbone und auf die Auflösung von $256\times 256$ Pixeln, so erreicht PatchCore mit einem Wide ResNet-50 Backbone eine \
Instanzklassifiziergungsgenauigkeit (AUROC) von \num{99,1} mit einer Reduktion der Memory Bank auf \num{25}\%. Wird die Größe der Memory Bank auf \num{1}\% reduziert, \
verschlechtert sich der AUROC nur leicht auf \num{99,0}\%. Wie im Laufe dieses Kapitels noch zu sehen sein wird, ist die Reduzierung der Kardinalität der Memory Bank \
ein wichtiger Schritt, um die Laufzeit zu reduzieren. Die hier angewandte Methode des Coreset Subsamplings ist also ein wichtiger Bestandteil und eine Errungenschaft \ 
der Methode PatchCore.\\
Neben dem Erzeugen der Patch Feature ist die Nächste Nachbar Suche in der Memory Bank besonder laufzeitkritisch. In der Veröffentlichung lediglich eine kleine Randnotiz im Anhang, \
ist diese Suche mit \glqq FAISS\grqq{} (TODO --> ref und cite) implementiert. FAISS ist eine Bibliothek, entwickelt von Facebook's AI Research Department, die die Nächste Nachbar Suche \ 
enorm beschleunigt und im Laufe dieses Kapitels nochmal genauer erläuert und analysiert wird.\\
Insgesamt ist die Methode PatchCore zwar in ihrer Originalform eine ausgezeichnete Basis, aber für die Implementierung auf einem RaspberryPi 4B nur eingeschränkt geeignet.\
Es werden im Folgenden zahlreiche Adaptionen vorgestellt und evaluiert, die das Ziel haben, die Laufzeit zu reduzieren und dabei möglichst viel der Genauigkeit zu erhalten.\ 
\section{Testaufbau}\label{sec:Testaufbau}
In diesem Abschnitt wird die Testumgebung vorgestellt, die für die Evaluation der PatchCore Methode verwendet wurde.\ 
Dabei sind viele der hier aufgeführten Vorgehensweisen auf \ref{ch:EfficientAD} und \ref{ch:SimpleNet} übertragbar.\
\subsection*{Hardware}\label{subsec:Hardware}
Es stehen grundsätzlich zwei Testumgebungen zur Verfügung. Das Ziel ist es zwar, die Implementierung auf einem RaspberryPi 4B zu ermöglichen, \
auf dem Weg dorthin, ist eine potentere Hardware aber notwendig. \\
Die Entwicklungsgeschwindigkeit hängt zum einen auch von der Laufzeit der Trainingsphase ab, die auf einem RaspberryPi 4B sehr lange dauert. \
Außerdem sind Ergebnisse, die auf der Desktop-Hardware erzeugt wurden, im Falle der Genauigkeit ganzheitlich übertragbar, nehmen, aber nur einen Bruchteil der Zeit in Anspruch.\
So spielt die Hardware, auf der eine identische Methode ausgeführt wird, für die Instanzklassifiziergung keine Rolle.\
Sind also lediglich die Instanzklassifiziergungsgenauigkeiten in einem Abschnitt von Relevanz, weil keine oder bekannte Unterschiede in der Laufzeit bestehen, kann auch auf eine \
GPU zurückgegriffen werden.\\
Laufzeitmessungen werden über weite Teile dieser Arbeit auf der Desktop-Hardware durchgeführt. Zwar sind nicht nur die reine Rechenleistung zwischen den Prozessoren der beiden Geräten \
unterschiedlich, auch die CPU-Architektur (ARM vs. x86) spielt eine Rolle. Jedoch sind die Ergebnisse qualitativ übertragbar. Aufgrund der Vielzahl an Adaptionen, die im Laufe dieser Arbeit \
getestet werden, wurde sich dazu entschlossen, die Laufzeitmessungen nur dann auf dem RaspberryPi 4B durchzuführen, wenn entweder große relative Abweichungen zu den Messungen auf der Desktop-Hardware \
zu erwarten sind oder es sich um eine finale Konfiguration handelt.\\
Im Folgenden werden einige relevante Informationen zum Desktop-System aufgeführt.\\
\begin{itemize}
    \item CPU: AMD Ryzen 5 5600X (6 Kerne, 12 Threads, @ 3,7 GHz)
    \item RAM: 32 GB DDR4 @ 3200 MHz
    \item GPU: Nvidia GeForce RTX 3060Ti (8 GB GDDR6)
    \item OS: Ubuntu 23.10 (Linux, Kernel 6.2.0-generic)
\end{itemize}  
Detailierte Information zur Hardware des RaspberryPi finden sich in \ref{sec:RaspberryPi4B}.\\
\subsection{Software}\label{subsec:Software}
Wie in der Forschung weit verbreitet und auch in allen Veröffentlichungen, die in dieser Arbeit verwendet werden, wird die Programmiersprache \textbf{Python} verwendet.\
Es kommt dabei die Version \textit{3.10} zum Einsatz.\\
Ebenfalls der Konvention in der Forschung entsprechend, wird das \textbf{PyTorch} Framework in der Version \textit{2.0.1} verwendet.\
PyTorch ist ein Open-Source-Framework für maschinelles Lernen, das von Facebooks AI Research Lab (FAIR) entwickelt wurde. Es hat aufgrund seiner Flexibilität, \ 
seines dynamischen Berechnungsgraphen und seiner Benutzerfreundlichkeit in der Community für maschinelles Lernen und Deep Learning große Beliebtheit erlangt. \ 
PyTorch bietet eine Python-basierte Schnittstelle für die Entwicklung neuronaler Netze und anderer Modelle für maschinelles Lernen. \
kann mit PyTorch effizient abgebildet werden.\cite{pytorch}\\
Die Nächste Nachbar Suche wird mit der Bibliothek \textbf{FAISS} durchgeführt. FAISS ist eine Bibliothek, die von Facebooks AI Research Lab (FAIR) entwickelt wurde. \
Wie bereits im vorherigen Abschnitt erwähnt, wird die Nächste Nachbar Suche jedoch in den meisten Fällen mit der Bibliothek \textbf{FAISS} durchgeführt. \ 
FAISS (Facebook AI Similarity Search) ist eine leistungsstarke Bibliothek, die ebenfalls vom KI-Forschungsteam von Facebook (FAIR) für die effiziente und \ 
skalierbare Ähnlichkeitssuche und die Suche nach dem nächsten Nachbarn in großen Datensätzen entwickelt wurde. \
FAISS wurde insbesondere für die Verarbeitung hochdimensionaler Daten entwickelt und eignet sich daher besonders \ 
gut für Aufgaben, die Merkmalsvektoren beinhalten, wie z. B. Einbettungen aus Deep-Learning-Modellen. Es nutzt Techniken wie Indexstrukturen, Quantisierung \ 
und GPU-Beschleunigung, um Suchvorgänge erheblich zu beschleunigen.\cite{faiss} \\
Daneben werden bekannte Bibliotheken wie \textbf{numpy} oder \textbf{scikit-learn} verwendet. Zur besseren Organisation des Codes wird ein modularer Aufbau verwendet, \
der durch das Framework \textbf{pytorch lightning} ermöglicht wird.\\
\subsubsection*{Laufzeit- und AUROC-Messungen}
Die Laufzeitmessungen werden mit dem Python-Modul \textbf{time} bzw. der Methode \textbf{perf\_counter()} durchgeführt.\
Zunächst wird immer nur die Laufzeit für ein einzelnes Bild betrachtet. Erst im Anschluss wird mit dem Durchsatz (\glqq Throughput\grqq{}) die Laufzeit von einem Ensemble (Batch)
an Bildern betrachtet (TODO --> Ref). \\
Ein einzelnes Bild durchläuft, während einer Laufzeitmessung $3$ mal einen sogenannten \glqq Warm-Up\grqq{} Prozess, der im Wesentlichen dazu dient, \
mögliche Overheads in Form von Initialisierungsprozessen, die im Hintergrund ablaufen, auszuschließe und zusätzliche, die Hardware in einen authentischen thermischen Zustand zu bringen.\
Keiner dieser Prozesse geht in die Laufzeitmessung direkt ein. Diese folgt für jedes Bild einzeln, indem die Inferenz $5$ mal durchgeführt wird und die Laufzeiten gemittelt werden. \
Es werden hierbei $5$ Zeitpunkte innerhalb des Prozesses mit \textit{perf\_counter()} festgestellt. Diese sind:\
\begin{itemize}
    \item \textbf{Start}: Der Zeitpunkt, an dem die Inferenz beginnt.
    \item \textbf{Ende: Feature Extraktion}: Der Zeitpunkt, an dem die Feature Extraktion durch den Backbone abgeschlossen ist (\ref{subsec:ErzeugenDerPatchFeatures}).
    \item \textbf{Ende: Einbettungsprozess}: Der Zeitpunkt, an dem die Patch Feature vorliegen (\ref{subsec:ErzeugenDerPatchFeatures}).
    \item \textbf{Ende: Nächste Nachbar Suche}: Der Zeitpunkt, an dem die Nächse Nachbar Suche abgeschlossen ist.
    \item \textbf{Ende: Anomalieprozess}: Der Zeitpunkt, an dem der Anomaliegrad berechnet wurde und der damit Prozess abgeschlossen ist (\ref{subsec:BestimmenDesAnomaliegradesPatchcore}). 
\end{itemize}
Aus den Differenzen dieser Zeitstempel lassen sich dann präzise die Laufzeiten für die einzelnen Prozesse und den Gesamtprozess bestimmen. Da es jedoch zu Schwankungen in der Laufzeit \
kommt, ist eine Mittelwertbildung notwendig. Dies geschieht in zweifacher Hinsicht. Zunächst wird für jedes Bild über die $5$ Durchläufe gemittelt. \
Das wird für jedes Bild wiederholt, sodass für jedes Bild eine Laufzeit vorliegt. Aus diesen Laufzeiten wird dann ebenfalls der Mittelwert gebildet, der als eigentlicher Messwert für eine \
Konfiguration dient.\\
Anzumerken ist, dass in dieser Arbeit, wie bereits in \ref{sec:AUROC} erläutert, auf eine Segmentierung verzichtet wird. Dementsprechend wird dieser Prozess, soweit nicht für die \
Instanzklassifiziergung notwendig, übersprungen und insbesondere nicht laufzeittechnisch erfasst.\\
Ebenfalls wird der Initialisierungsprozess bzw. die Trainingsphase nur in exemplarischen Fällen betrachtet. Der Initialisierungsprozess ist einmalig und kann auch somit auch auf potenter Hardware \
durchgeführt werden. In einer produktiven Umgebung ist dieser Trainingsprozess ohnehin nicht relevant, weil bereits abgeschlossen.\\
Wie in (TODO --> ref) zu sehen, hängt die Laufzeit, genauer gesagt, die NN-Suche, stark von der Kardinalität von der Memory Bank $\mathcal{M}$ ab. In der Literatur allgemein üblich ist, \
dass ein relatives Subsampling stattfindet. Wie wir \ref{tab:mvtecad_overview} entnehmen können, hat jede Kategorie unterschiedlich viele Bilder im Trainingsdatensatz und teilweise verschiedene\
Auflösungen, wodurch sich eine unterschiedliche absolute Anzahl an Patch Featuren ergeben. Um die Laufzeitmessungen vergleichbar zu machen, wird die Kardinalität der Memory Bank \
in den meisten Fällen auf $\num{1000}$ gesetzt, wenn nicht anders angegeben. Dies dient vor allem dazu, die Laufzeitmessungen für alle Klassen gleichermaßen geltend zu machen.\
In diesem Sinne werden auch die Auflösungen der Bilder auf $256\times 256$ Pixel gesetzt, was dem Vorgehen der meisten Veröffentlichungen in diesem Bereich entspricht. Der Skalierungsprozess wird \
dabei nicht als Teil der Laufzeit betrachtet. \\
Dieser ermöglicht, dass die Laufzeitmessung für eine Konfiguration für eine Klasse ausreichend ist. Dies reduziert den Zeitaufwand für eine Messung einer Konfiguration über alle Klassen deutlich,\
weil zum einen auf die Wiederholungen verzichtet werden kann, andererseits für die verbleibende Bestimmung der AUROC auch eine deutlich schneller arbeitende GPU verwendet werden kann.\\
Wie bereits in \ref{sec:AUROC} ausgeführt, ist die AUROC eine ideale Metrik um die Güte eines Anomaliedetektors zu bewerten.\
Hierzu werden zunächst für alle Bilder im Testdatensatz die Anomaliegrade berechnet. Auf Grundlage dieser Werte, wird dann die AUROC berechnet.\
Wie in \ref{subsec:CoresetSubsampling} ausgeführt, wird bei der Berechnung der Elemente, die in die Memory-Bank übernommen werden, ein Algorithmus verwendet, der 
randomisiert arbeitet. Um diesen zufälligen Einfluss zu minimieren, werden aus den identischen Patch Featuren $5$ Memory Banks $\mathcal{M}$ erzeugt, deren AUROC ebenfalls gemittelt wird,\
um einen möglichst konsistenten Schätzer zu erhalten. Das geschieht für alle Klassen aus MVTecAD (\ref{sec:DatensatzMVTecAD}) und der Klasse des einigen Datensatzes (Granulat, \ref{sec:EigenerDatensatz}).\
Während für den eigenen Datensatz der AUROC explizit angegeben wird, wird für die Klassen aus MVTecAD nur der Mittelwert über alle Klassen angegeben. Die einzelnen Ergebnisse sind aber archiviert und können \
beim Autor erfragt werden.\\
Die meisten der hier zu sehenden Plots wurden mit \textbf{tikz} und \textbf{matplotlib} direkt auf Grundlage der Messergebnisse erzeugt. Die Annotationen sind sinnvoll gerundet, um eine bessere \
Lesbarkeit zu ermöglichen. \\
Die Grundlage der Implementierung der Methode PatchCore liefert dabei die offizielle Implementierung \cite{patchcore} und eine inoffizielle Implementierung \cite{unofficialimplementation}. Diese wurden jedoch jeweils derart modifiziert, dass
nur noch wenige Elemente der ursprünglichen Implementierung übrig geblieben sind. Der gesamte Code mit dem die folgenden Ergebnisse und Messungen erzeugt wurden, ist abrufbar.\
\section{Adaptionen und Messergebnisse}\label{sec:Adaptionen}
Der hier beginnende Abschnitt ist der umfangreichste dieser Arbeit. Er besteht als vielen Adaptionen, die im Laufe der Arbeit durchgeführt wurden, um die Laufzeit zu reduzieren.\
Jeder Unterabschnitt beschäftigt sich damit mit einer Adaption oder einer Kombination von Adaptionen. \ 
Zunächst wird dabei, die Idee hinter der Adaption erläutert. Messergebnisse werden dann präsentiert und diskutiert. Schließlich findet eine Einordnung und Bewertung statt.\
\subsection{Originalmethode}
Zunächst wird die Originalmethode ohne Adaption betrachtet. Es wird also die Methode PatchCore mit einem Wide ResNet-50 Backbone und einer Auflösung von $256\times 256$ Pixeln verwendet.\
Die Laufzeitmessungen wurden mit der CPU des Desktop-PCs durchgeführt.\\
In \ref{fig:patchcoreoriginal} ist die Laufzeit für die einzelnen Prozesse und den Gesamtprozess zu sehen, sowie die erreichte AUROC Klassifizierungsgenauigkeit.\
Es lässt sich erkennen, dass die Angaben aus dem Paper sich verifizieren lassen. Es kann daraus abgeleitet werden, dass die im Rahmen dieser Arbeit erarbeitete Implementierung \
korrekt ist.\\
Eine schon besprochene Bemerkung kann ebenfalls abgelesen werden. Die von PatchCore verwendete Subsampling-Methode ist in der Lage, die Kardinalität der Memory Bank $\mathcal{M}$ \
deutlich zu reduzieren, ohne die AUROC Klassifizierungsgenauigkeit zu stark zu beeinflussen. Eindeutig ist auch zu erkennen, dass diese Reduktion der Kardinalität \
ein wesentlicher Bestandteil ist, möchte man eine möglichst geringe Laufzeit erreichen. Trotz Verwendung der State-of-the-Art Methoden, die von FAISS bereitgestellt werden, \
ist die Nächste Nachbar Suche der laufzeitkritischste Prozess, wenn ein Subsampling $>10\%$ verwendet werden soll.\\
Am Granulatdatensatz lässt sich sogar feststellen, dass zumindest in einzelnen Fällen, ein Subsampling der Instanzklassifiziergungsgenauigkeit sogar zuträglich sein kann.\
Wie bereits ausgeführt, wird im Rahmen dieser Arbeit in den meisten Fällen kein relatives Subsampling durchgeführt, sondern eine absolute Kardinalität von $\num{1000}$ verwendet.\
Für manche Klassen mit wenigen Trainingsbeispielen und geringerer Auflösung bedeutet das, es werden mehr Patch Feature in der Memory Bank sein, als bei einem relativen Subsampling mit $1\%$.\
In den meisten Fällen läge die relative Subsamplingrate, die eine Kardinalität von $\num{1000}$ erzeugt, bei $<1\%$. Berechnet man den Mittelwert über alle Klassen, so ergibt sich eine \
durchschnittliche relative Subsamplingrate von $\approx \num{0,6}\%$. Die erzeugten Ergebnisse entsprechen somit den Erwartungen und den Ergebnissen aus der Veröffentlichung.\\
\begin{figure}[h]
    \centering
    \input{tikz/slide1edited}
    \caption{PatchCore: Originalmethode mit unterschiedlicher Anzahl an Patch Featuren in Memory Bank.}
    \label{fig:patchcoreoriginal}
\end{figure}
Der in der Originalmethode verwendete Einbettungsprozess, der in \ref{subsec:ErzeugenDerPatchFeatures} beschrieben ist, bietet einen Parameter $d$, der die Länge der Patch Features bestimmt.\
In der \ref{fig:patchcoreoriginal} wurde keine Dimensionsreduktion durchgeführt, indem $d$ der Länge der aus Layer3 ($j=3$) extrahierten Feature entspricht, nämlich $1024$.\
Mithilfe eines kleineren Parameters $d$ kann die Laufzeit weiter reduziert werden. In \ref{fig:patchcoreoriginal} ist die Laufzeit für unterschiedliche Werte von $d$ und zwei verschiedenen \ 
Methoden zur Bestimmung der Nächsten Nachbarn und den korrespondierenden Distanzen zu sehen. Diese Abbildung inkludiert bei (1) und (4) Einbettungsmethoden, die nicht in der Originalmethode \ 
vorgeschlagen worden sind und in Abschnitt (TODO --> ref) erläutert werden.\
An dieser Stelle ist wichtig, dass die Merkmalslänge dadurch nochmal größer ausfällt ($d=1536$) als bei der Originalmethde und dem größten sinvollen Wert für $d=1024$. \
Anhand von \ref{fig:patchcorecdist} können zweierlei Phänomene erkannt werden.\\
\begin{figure}[h]
    \centering
    \input{tikz/slide2edited}
    \caption{FAISS im Vergleich mit SciPy's cdist und unterschiedlichen Merkmalslängen $d$.}
    \label{fig:patchcorecdist}
\end{figure}
Zum einen ist die in der Veröffentlichung verwendete Methode zur Bestimmung der Nächsten Nachbarn, die auf FAISS basiert, deutlich schneller als das Berechnen der Distanzen mit \
SciPy's Funktion cdist\cite{cdist}. Dabei ist diese Methode, wie der Name bereits nahelegt, in der Programmiersprache C implementiert und kann somit als sehr performant angesehen werden.\
Es wird allerdings zu jedem Patch Feature in $\mathcal{P}\left(x_{i}\right)$ die Distanz zu jedem Patch Feature in $\mathcal{M}$ explizit berechnet. \
FAISS beschleunigt diesen Ansatz enorm durch Methoden wie Quantisierung und Indexstrukturen. Für eine genauere Erläuterung der Funktionsweise von FAISS wird auf \cite{faiss} verwiesen.\
Der positive Effekt durch FAISS auf die Laufzeit steigt naheliegenderweise mit der Länge der Patch Features, ist aber auch bei $d=384$ schon deutlich zu erkennen.\\
Das zweite Phänomen, das hier kurz besprochen werden soll, ist, dass FAISS deutlich weniger unter dem als \glqq Curse of Dimensionality\grqq{} (\textit{dt.:} Fluch der Dimensionalität) bezeichneten \
Problem leidet. Der Fluch der Dimensionalität bezieht sich auf das Phänomen, dass der euklidische Abstand zwischen Punkten in einem hochdimensionalen Raum mit zunehmender Anzahl von \ 
Dimensionen an Aussagekraft verliert, so dass es schwierig wird, die Ähnlichkeit oder den Abstand zwischen Punkten genau zu messen.(TODO --> find ref)\
Durch Quantisierung bzw. aufteilen in kleinere Vektoren, die dann in Indexstrukturen abgelegt werden, kann FAISS dieses Problem umgehen. Es lässt sich in \ref{fig:patchcorecdist} erkennen, \
dass, je größer $d$ ist, dieser negative Effekt immer stärker sich in der Genauigkeit der Instanzklassifiziergung niederschlägt. So kommen die beiden Suchverfahren bei $d=384$ noch auf \
recht ähnliche Ergenisse ((2) und (3)), während bei $d=1536$ ((1) und (4)) die Instanzklassifiziergungsgenauigkeit bei der Verwendung von cdist deutlich schlechter ist als bei der Verwendung von FAISS.\\
Es lässt sich also festhalten, dass die Verwendung von FAISS essentiell ist, einerseits um eine präzise Anomaliedetektion auch mit hochdimensionalen Merkmalsvektoren zu ermöglichen, \
andererseits um die Laufzeit zu reduzieren.\\
\subsection{Feature Extraktor - Wahl des Backbones}
Es konnte bereits in \ref{fig:patchcorecdist} anhand von (5 - default) erkannt werden, dass die Feature Extraktion, also der \glqq forward pass\grqq{} durch den Backbone, \
einen Großteil der Laufzeit für sich in Anspruch nimmt. Naheliegend ist deshalb hier anzusetzten. \
Es steht eine sehr große Auswahl an möglichen Architekturen zur Auswahl. EfficientNets \cite{efficientnet} und DenseNets \cite{densenet} wurden bereits im Zusammenhang mit PatchCore Ensemble erwähnt.\
In vielen Veröffentlichung wurden Studien durchgeführt und festgestellt, dass insbesondere EfficientNets eine valide Wahl darstellen, aber gegenüber den hier in dieser Arbeit verwendeten Architekturen \
keine signifikanten Vorteile bieten. Es wurde sich deshalb entschieden, ausschließlich mit bewährten ResNet Architekturen zu arbeiten und nur Architekturen, die aus anderen Gründen interessant sind, \
im Rahmen dieser Arbeit quantitativ zu evaluieren. \\
Die in jüngerer Vergangenheit im Bereich der Künstlichen Intelligenz sehr erfolgreich verwendeten %\glqq Transformer\grqq{} basierten Architekturen, wie DeiT %\cite{deit} %oder CaiT \cite{cait}, bieten \
auch in der Unüberwachten Anomaliedetekion ein spannendes Potential. Die Methoden FastFlow \cite{fastflow} und CAINNFlow \cite{cainnflow} erfolgreich eingesetzt. In beiden Veröffentlichungen werden \
neben diesen Transformer-Architekturen auch ResNet-Architekturen verwendet, die in ihrer Leistungsfähigkeit nicht signifikant schlechter abschneiden.\
Da Transformer-Architekturen im Allgemeinen, insbesondere bei der Berechnung ohne GPU, deutlich laufzeitkritischer sind, als ResNets, wird in dieser Arbeit auch auf die Verwendung von Transformer-Architekturen \
verzichtet. Zwar gibt es Bestrebungen, die Laufzeit von Transformer basierten Netzwerken zu reduzieren, die auch durchaus erfolgreich sind. Allerdings ist eine der schnellsten und kompaktesten Varianten \
von Transformer basierten Netzwerken, die Architektur MobileViT \cite{mobilevit} immer noch deutlich langsamer als gängige CNN Architekturen (Tabelle 3 in \cite{mobilevit}).
Im Folgenden werden dementsprechend vor allem ResNets behandelt. Es wird aber auch auf eine verhältnismäßig neue Architektur, die \glqq ConvNexts\grqq{}, eingegangen, weil diese in bislang noch keiner \
dem Autor bekannten Veröffentlichung untersucht wurde. Außerdem werden leichtgewichtige Feature Extraktoren, die durch Wissens Distilation (TODO --> ref) erzeugt wurden, untersucht.\\
Auch die Vielzahl an ResNet Varianten verlangt eine profunde Vorauswahl. In Frage kommen sämtliche Architekturen, die eine kürzere Laufzeit verpricht, \
als die in der Originalmethode verwendete Architektur Wide ResNet-50.\
Das sind, wie bereits in \ref{tab:resnet-comparison} zu sehen, ResNet 34 und ResNet 18. Außerdem erscheint das ResNet50 als ein sinnvoller Backbone.\
\subsubsection{ResNet}
In diesem ausführlichen Abschnitt werden die Architekturen ResNet 18, ResNet 34 und ResNet 50 untersucht.\
Es wird außerdem untersucht, welche Kombination an Hierarchielevel $j$ sinnvoll sind.\
Abschließend findet eine Bewertung statt mit dem Ziel, eine Variante auszuwählen, die als Grundlage für weitere \
Untersucchungen dient. \
\paragraph{ResNet 50}
....
\paragraph{ResNet 34}
... 
\paragraph{ResNet 18}
...
\paragraph{Patch Description Network (PDN) - Wissensdistillation mit Wide ResNet 101 und PatchCore Einbettung}
Wie in \ref{ch:EfficientAD} noch zu sehen sein wird, kann über Wissensdistillation ein den spezifischen Anforderungen angepasster \
alternativer Feature Exktraktor erzeugt werden. Ein Wide ResNet kombiniert mit dem Einbettungsprozess aus PatchCore generiert in hierbei \
die Trainingsbeispiele, um den sogenannten Patch Description Network (PDN) zu trainieren.\\ 
\begin{figure}[h]
    \centering
    \input{tikz/slidepdncomparisonedited}
    \caption{PatchCore: ResNet 18, 34 und 50 mit unterschiedlichen Hierarchieleveln $j$.}
    \label{fig:patchcoreresnet}
\end{figure}
% Es werden zahlreiche Bibliotheken verwendet, von denen im nachfolgenden einige besonders relevante aufgeführt werden.\\
% \begin{itemize}
%     \item \textbf{torch} (Version 2.0.1)\\
%     \item numpy
% \end{itemize}
% \newpage
% \input{tikz/test2newnew}\\
% \input{tikz/test2new}
% \input(tikz/test2new)   
% \input(tikz/test2newnew)
% \input{tikz/test2new}
% \input(tikz/test2new)
% This file was created with tikzplotlib v0.10.1.
% \begin{tikzpicture}

%     \definecolor{crimson}{RGB}{220,20,60}
%     \definecolor{darkgoldenrod}{RGB}{184,134,11}
%     \definecolor{darkgray176}{RGB}{176,176,176}
%     \definecolor{gray}{RGB}{128,128,128}
%     \definecolor{lightgray204}{RGB}{204,204,204}
%     \definecolor{purple}{RGB}{128,0,128}
%     \definecolor{slateblue}{RGB}{106,90,205}
    
%     \begin{axis}[
%     legend cell align={left},
%     legend style={
%       fill opacity=0.8,
%       draw opacity=1,
%       text opacity=1,
%       at={(1.15,0.06)},
%       anchor=south east,
%       draw=lightgray204
%     },
%     tick align=outside,
%     tick pos=left,
%     title={tmp},
%     x grid style={darkgray176},
%     xmin=-0.538, xmax=2.498,
%     xtick style={color=black},
%     xtick={0,1,2},
%     xticklabels={
%       {
%     PatchCore:
%     Search, Embedding (192)
%     Adapted Score Calc
%     192 Merkmalsl�nge},
      
%     PatchCore:
%     Embedding (384)
%     Adapted Score Calc + Own KNN
%     384 Merkmalsl�nge,
      
%     PatchCore:
%     Embedding (192)
%     Adapted Score Calc + Own KNN
%     192 Merkmalsl�nge
%     },
%     y grid style={darkgray176},
%     ylabel={(Lauf-) Zeit [ms] (Mittelwert)},
%     ymin=0, ymax=100,
%     ytick style={color=black},
%     ytick={0,20,40,60,80,100},
%     yticklabels={{0,0},{20,0},{40,0},{60,0},{80,0},{100,0}}
%     ]
%     \draw[draw=none,fill=crimson] (axis cs:-0.4,0) rectangle (axis cs:0,9.22161102294922);
%     \addlegendimage{ybar,ybar legend,draw=none,fill=crimson}
%     \addlegendentry{Merkmalsextraktion}
    
%     \draw[draw=none,fill=crimson] (axis cs:0.6,0) rectangle (axis cs:1,9.24572658538818);
%     \draw[draw=none,fill=crimson] (axis cs:1.6,0) rectangle (axis cs:2,10.9772291183472);
%     \draw[draw=none,fill=purple] (axis cs:-0.4,9.22161102294922) rectangle (axis cs:0,15.6351671218872);
%     \addlegendimage{ybar,ybar legend,draw=none,fill=purple}
%     \addlegendentry{Einbettung}
    
%     \draw[draw=none,fill=purple] (axis cs:0.6,9.24572658538818) rectangle (axis cs:1,16.2714972496033);
%     \draw[draw=none,fill=purple] (axis cs:1.6,10.9772291183472) rectangle (axis cs:2,18.726692199707);
%     \draw[draw=none,fill=slateblue] (axis cs:-0.4,15.6351671218872) rectangle (axis cs:0,16.8189399242401);
%     \addlegendimage{ybar,ybar legend,draw=none,fill=slateblue}
%     \addlegendentry{NN-Suche}
    
%     \draw[draw=none,fill=slateblue] (axis cs:0.6,16.2714972496033) rectangle (axis cs:1,87.2139410972595);
%     \draw[draw=none,fill=slateblue] (axis cs:1.6,18.726692199707) rectangle (axis cs:2,58.6836013793945);
%     \draw[draw=none,fill=darkgoldenrod] (axis cs:-0.4,16.8189399242401) rectangle (axis cs:0,17.1661679446697);
%     \addlegendimage{ybar,ybar legend,draw=none,fill=darkgoldenrod}
%     \addlegendentry{Berechnung Scores}
    
%     \draw[draw=none,fill=darkgoldenrod] (axis cs:0.6,87.2139410972595) rectangle (axis cs:1,87.5636786222458);
%     \draw[draw=none,fill=darkgoldenrod] (axis cs:1.6,58.6836013793945) rectangle (axis cs:2,59.0766642689705);
%     \draw (axis cs:-0.2,9.22161102294922) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{9,22};
%     \draw (axis cs:0.8,9.24572658538818) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{9,25};
%     \draw (axis cs:1.8,10.9772291183472) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{10,98};
%     \draw (axis cs:-0.2,17.1661679446697) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{17,17};
%     \draw (axis cs:0.8,87.5636786222458) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{87,56};
%     \draw (axis cs:1.8,59.0766642689705) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{59,08};
%     \end{axis}
    
%     \begin{axis}[
%     axis y line=right,
%     tick align=outside,
%     x grid style={darkgray176},
%     xmin=-0.538, xmax=2.498,
%     xtick pos=left,
%     xtick style={color=black},
%     xtick={0,1,2},
%     xticklabels={
%       {
%     PatchCore:
%     Search, Embedding (192)
%     Adapted Score Calc
%     192 Merkmalsl�nge},
      
%     PatchCore:
%     Embedding (384)
%     Adapted Score Calc + Own KNN
%     384 Merkmalsl�nge,
      
%     PatchCore:
%     Embedding (192)
%     Adapted Score Calc + Own KNN
%     192 Merkmalsl�nge
%     },
%     y grid style={darkgray176},
%     ylabel={AUROC [\%]},
%     ymin=50, ymax=105,
%     ytick pos=right,
%     ytick style={color=black},
%     yticklabel style={anchor=west}
%     ]
%     \draw[draw=none,fill=black] (axis cs:0.04,0) rectangle (axis cs:0.16,98.5661745071411);
%     \addlegendimage{ybar,ybar legend,draw=none,fill=black}
%     \addlegendentry{Eigene Datensatz}
    
%     \draw[draw=none,fill=black] (axis cs:1.04,0) rectangle (axis cs:1.16,98.5031485557556);
%     \draw[draw=none,fill=black] (axis cs:2.04,0) rectangle (axis cs:2.16,98.5714256763458);
%     \draw[draw=none,fill=gray] (axis cs:0.24,0) rectangle (axis cs:0.36,97.7773904800415);
%     \addlegendimage{ybar,ybar legend,draw=none,fill=gray}
%     \addlegendentry{MVTechAD (Mittelwert)}
    
%     \draw[draw=none,fill=gray] (axis cs:1.24,0) rectangle (axis cs:1.36,97.8362500667572);
%     \draw[draw=none,fill=gray] (axis cs:2.24,0) rectangle (axis cs:2.36,97.896546125412);
%     \draw (axis cs:0.1,98.5661745071411) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{98,6};
%     \draw (axis cs:1.1,98.5031485557556) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{98,5};
%     \draw (axis cs:2.1,98.5714256763458) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{98,6};
%     \draw (axis cs:0.3,97.7773904800415) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{97,8};
%     \draw (axis cs:1.3,97.8362500667572) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{97,8};
%     \draw (axis cs:2.3,97.896546125412) ++(0pt,3pt) node[
%       scale=0.5,
%       anchor=south,
%       text=black,
%       rotate=0.0
%     ]{97,9};
% \end{axis}
    
% \end{tikzpicture}
    
% % $$

% % % \begin{aligned}
% % m^{\text {test }, *}, m^* & =\underset{m^{\text {test }} \in \mathcal{P}\left(x^{\text {test }}\right)}{\arg \max } \underset{m \in \mathcal{M}}{\arg \min }\left\|m^{\text {test }}-m\right\|_2 \\
% % s^* & =\left\|m^{\text {test }, *}-m^*\right\|_2 .
% % % \end{aligned}
% % $$
% % % \begin{tabular}{l}
% %     \hline Algorithm 1: PatchCore memory bank. \\
% %     \hline Input: Pretrained $\phi$, hierarchies $j$, nominal data \\
% %     \\
% %     $\quad \mathcal{X}_N$, stride $s$, patchsize $p$, coreset target $l$, \\
% %     random linear projection $\psi$. \\
% %     Output: Patch-level Memory bank $\mathcal{M}$. \\
% %     Algorithm: \\
% %     $\mathcal{M} \leftarrow\{\}$ \\
% %     for $x_i \in \mathcal{X}_N$ do \\
% %     | $\mathcal{M} \leftarrow \mathcal{M} \cup \mathcal{P}_{s, p}\left(\phi_j\left(x_i\right)\right)$ \\
% %     end \\
% %     /* Apply greedy coreset selection. \\
% %     $\mathcal{M}_C \leftarrow\{\}$ \\
% %     for $i \in[0, \ldots, l-1]$ do \\
% %     $\quad m_i \leftarrow \underset{m \in \mathcal{M}-\mathcal{M}_C n \in \mathcal{M}}{\arg \max }\|\psi(m)-\psi(n)\|_2$ \\
% %     $\quad \mathcal{M}_C \leftarrow \mathcal{M}_C \cup\left\{m_i\right\}$ \\
% %     end \\
% %     $\mathcal{M} \leftarrow \mathcal{M}_C$
% % \end{tabular}

% % $$
% % \begin{aligned}
% % & \hline \text { Algorithm 1: PatchCore memory bank. } \\
% % & \hline \text { Input: Pretrained } \phi \text {, hierarchies } j \text {, nominal data } \\
% % & \\
% % & \quad \mathcal{X}_N \text {, stride } s \text {, patchsize } p \text {, coreset target } l, \\
% % & \text { random linear projection } \psi \text {. } \\
% % & \text { Output: Patch-level Memory bank } \mathcal{M} . \\
% % & \text { Algorithm: } \\
% % & \mathcal{M} \leftarrow\{\} \\
% % & \text { for } x_i \in \mathcal{X}_N \text { do } \\
% % & \text { | } \mathcal{M} \leftarrow \mathcal{M} \cup \mathcal{P}_{s, p}\left(\phi_j\left(x_i\right)\right) \\
% % & \text { end } \\
% % & \text { /* Apply greedy coreset selection. } \\
% % & \mathcal{M}_C \leftarrow\{\} \\
% % & \text { for } i \in[0, \ldots, l-1] \text { do } \\
% % & \quad m_i \leftarrow \underset{m \in \mathcal{M}-\mathcal{M}_C n \in \mathcal{M}}{\arg \max }\|\psi(m)-\psi(n)\|_2 \\
% % & \quad \mathcal{M}_C \leftarrow \mathcal{M}_C \cup\left\{m_i\right\} \\
% % & \text { end } \\
% % & \mathcal{M} \leftarrow \mathcal{M}_C
% % \end{aligned}
% % $$

% \section{Baseline}
% \label{sec:Baseline}
% Hallo

% \section{Adaptionen}
% \label{sec:Adaptionen}
% Hallo2